{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toronto_Segmenting_Clustering.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "xAsgwlvDFySo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing Packages**"
      ]
    },
    {
      "metadata": {
        "id": "RakWpGi8z9eo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "d82c441e-b4f5-49b3-9ab7-2ae4ab62accc"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # library to handle data in a vectorized manner\n",
        "\n",
        "import pandas as pd # library for data analsysis\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "import json # library to handle JSON files\n",
        "\n",
        "!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
        "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
        "\n",
        "import requests # library to handle requests\n",
        "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
        "\n",
        "# Matplotlib and associated plotting modules\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as colors\n",
        "\n",
        "# import k-means from clustering stage\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
        "import folium # map rendering library\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup as BSoup\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-61f27f5272a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNominatim\u001b[0m \u001b[0;31m# convert an address into latitude and longitude values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m \u001b[0;31m# library to handle requests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Yo2s7D6FF6zr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Scraping Data from Wikipedia**"
      ]
    },
    {
      "metadata": {
        "id": "9oyHqU4w0XdZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BASE_URI = 'https://en.wikipedia.org'\n",
        "page = requests.get('https://en.wikipedia.org/wiki/List_of_neighbourhoods_in_Toronto')\n",
        "soup = BSoup(page.content, 'html.parser')\n",
        "\n",
        "boroughs_list = soup.select(\".mw-parser-output h3\")\n",
        "neighbours_list = soup.select(\".mw-parser-output div table.multicol\")\n",
        "\n",
        "city_info = list()\n",
        "\n",
        "column_names = ['Borough', 'Neighborhood', 'Latitude', 'Longitude'] \n",
        "\n",
        "# instantiate the dataframe\n",
        "neighborhoods = pd.DataFrame(columns=column_names)\n",
        "\n",
        "def geo_calculator(value):\n",
        "  if len(value) == 4:\n",
        "    decimal = float(value[0]) + (float(value[1])/60) + (float(value[2])/3600)\n",
        "  elif len(value) == 3:\n",
        "    decimal = float(value[0]) + (float(value[1])/60)\n",
        "  elif len(value) == 2:\n",
        "    decimal = float(value[0])\n",
        "  else:\n",
        "    raise ValueError\n",
        "  return decimal if value[-1].strip() in ['N', 'E'] else -decimal\n",
        "\n",
        "def scrape_geodata(url):\n",
        "  page_ = requests.get(url)\n",
        "  soup_ = BSoup(page_.content, 'html.parser')\n",
        "  lat_elem = soup_.select('.geo-default .geo-dms .latitude')\n",
        "  lon_elem = soup_.select('.geo-default .geo-dms .longitude')\n",
        "  if lat_elem:\n",
        "    if 'append' in dir(lat_elem):\n",
        "      lat_elem = lat_elem[0]\n",
        "    lt = re.split(u'[°′″]', lat_elem.get_text())\n",
        "    latitude = geo_calculator(lt)\n",
        "  \n",
        "  else:\n",
        "    lat_elem = soup_.select('.geo-default .geo')[0].get_text()\n",
        "    latitude = lat_elem.split('; ')[0]\n",
        "\n",
        "  if lon_elem:\n",
        "    if 'append' in dir(lon_elem):\n",
        "      lon_elem = lon_elem[0]\n",
        "    ln = re.split(u'[°′″]', lon_elem.get_text())\n",
        "    longitude = geo_calculator(ln)\n",
        "\n",
        "  else:\n",
        "    lon_elem = soup_.select('.geo-default .geo')[0].get_text()\n",
        "    longitude = lon_elem.split('; ')[1]\n",
        "\n",
        "  return latitude, longitude\n",
        "\n",
        "def get_geodata(url):\n",
        "  geolocator = Nominatim()\n",
        "  geo_name = url.split('/')[-1].replace('_', ' ')\n",
        "  location = geolocator.geocode(geo_name)\n",
        "  if location:\n",
        "    return location.latitude, location.longitude\n",
        "  else:\n",
        "    lat, lon = scrape_geodata(BASE_URI + url)\n",
        "    return lat, lon\n",
        "\n",
        "neighbourhood_data = list()\n",
        "for index in range(len(neighbours_list)):\n",
        "  this_borough = boroughs_list[index].find('a').get_text()\n",
        "  neighbours_in_borough = neighbours_list[index].select('td li')\n",
        "  for neighbours in neighbours_in_borough:\n",
        "    neighbour_dict = dict()\n",
        "    neighbour_url = neighbours.find('a').get('href')\n",
        "    neighbour_name = neighbours.find('a').get_text()\n",
        "    neighbour_dict['Borough'] = this_borough.encode('ascii', 'ignore')\n",
        "    neighbour_dict['Neighborhood'] = neighbour_name.encode('ascii', 'ignore')\n",
        "    neighbour_dict['URI'] = BASE_URI + neighbour_url\n",
        "    neighbour_dict['Latitude'], neighbour_dict['Longitude'] = get_geodata(neighbour_url)\n",
        "    neighbourhood_data.append(neighbour_dict)\n",
        "\n",
        "neighbours = pd.DataFrame(columns=['Borough', 'Neighborhood', 'Latitude', 'Longitude'])\n",
        "for data in neighbourhood_data:\n",
        "  data.pop('URI')\n",
        "  neighbours = neighbours.append(data, ignore_index=True)\n",
        "\n",
        "# print(neighbours)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulyGmJa9GFQR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Making a Folium Map for Toronto**"
      ]
    },
    {
      "metadata": {
        "id": "OURR1af00yls",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "address = 'Toronto, Canada'\n",
        "geolocator = Nominatim()\n",
        "location = geolocator.geocode(address)\n",
        "latitude, longitude = location.latitude, location.longitude\n",
        "# print('\\n>>> Latitude and Longitude of Toronto: {}, {}'.format(latitude, longitude))\n",
        "\n",
        "# Creating Map of Toronto:\n",
        "map_toronto = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
        "for lt, ln, borough, neighbour in zip(neighbours['Latitude'], neighbours['Longitude'], neighbours['Borough'], neighbours['Neighborhood']):\n",
        "  label = '{}, {}'.format(neighbour, borough)\n",
        "  label = folium.Popup(label, parse_html=True)\n",
        "  try:\n",
        "    folium.CircleMarker(\n",
        "      [lt, ln],\n",
        "      radius=5,\n",
        "      popup=label,\n",
        "      color='blue',\n",
        "      fill=True,\n",
        "      fill_color='#3186cc',\n",
        "      fill_opacity=0.7).add_to(map_toronto)\n",
        "  except TypeError:\n",
        "    pass\n",
        "print('\\n\\t *** Mapping Toronto ***')\n",
        "# print(map_toronto)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QYHVAZxtGSpq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Adding Markers to Toronto Map**"
      ]
    },
    {
      "metadata": {
        "id": "yvcRDUSr0-Nn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# toronto data\n",
        "toronto_data = neighbours.reset_index(drop=True)\n",
        "\n",
        "map_toronto = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
        "\n",
        "# add markers to map\n",
        "for lat, lng, label in zip(toronto_data['Latitude'], toronto_data['Longitude'], toronto_data['Neighborhood']):\n",
        "    label = folium.Popup(label, parse_html=True)\n",
        "    folium.CircleMarker(\n",
        "        [lat, lng],\n",
        "        radius=5,\n",
        "        popup=label,\n",
        "        color='blue',\n",
        "        fill=True,\n",
        "        fill_color='#3186cc',\n",
        "        fill_opacity=0.7,\n",
        "        parse_html=False).add_to(map_toronto)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "84edxtmnGZeB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pulling data of Top 100 venues within 500 m of Toronto from Foursquare API**"
      ]
    },
    {
      "metadata": {
        "id": "m5JqIN1I4LW0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CLIENT_ID = 'RUQCXQNNJJGBXFNFM0305GOE242UGPX0QM4FG3L34TDU2T3K'\n",
        "CLIENT_SECRET = 'KXOXMOXDQGGENMPD2DWG4RDQJXFUJ5NZIATE4IXBOQLM3KOZ'\n",
        "VERSION = '20180410'\n",
        "\n",
        "neighborhood_latitude = toronto_data.loc[0, 'Latitude'] # neighborhood latitude value\n",
        "neighborhood_longitude = toronto_data.loc[0, 'Longitude'] # neighborhood longitude value\n",
        "\n",
        "neighborhood_name = toronto_data.loc[0, 'Neighborhood'] # neighborhood name\n",
        "radius = 500\n",
        "LIMIT = 100\n",
        "url = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude, VERSION, radius, LIMIT)\n",
        "results = requests.get(url).json()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nk3WDx-EG0bY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Extracting the category of the venue**"
      ]
    },
    {
      "metadata": {
        "id": "VrlsY-7W4NUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "a20ede23-5cfe-4443-853c-020bbd428fd3"
      },
      "cell_type": "code",
      "source": [
        "def get_category_type(row):\n",
        "  try:\n",
        "    categories_list = row['categories']\n",
        "  except:\n",
        "    categories_list = row['venue.categories']\n",
        "        \n",
        "  if len(categories_list) == 0:\n",
        "    return None\n",
        "  else:\n",
        "    return categories_list[0]['name']\n",
        "\n",
        "venues = results['response']['groups'][0]['items']\n",
        "    \n",
        "nearby_venues = json_normalize(venues) # flatten JSON\n",
        "\n",
        "# filter columns\n",
        "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
        "nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
        "\n",
        "# filter the category for each row\n",
        "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
        "\n",
        "# clean columns\n",
        "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1997431c5d14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcategories_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mvenues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'groups'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnearby_venues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvenues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flatten JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "IvBEyb9oHLO2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Handling for every neighbouhood in Toronto**"
      ]
    },
    {
      "metadata": {
        "id": "msAqpaF94ORM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
        "  \n",
        "  venues_list=[]\n",
        "  for name, lat, lng in zip(names, latitudes, longitudes):\n",
        "    print(name)\n",
        "        \n",
        "    # create the API request URL\n",
        "    url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
        "      CLIENT_ID, \n",
        "      CLIENT_SECRET, \n",
        "      VERSION, \n",
        "      lat, \n",
        "      lng, \n",
        "      radius, \n",
        "      LIMIT)\n",
        "        \n",
        "    # make the GET request\n",
        "    results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
        "    \n",
        "    # return only relevant information for each nearby venue\n",
        "    venues_list.append([(\n",
        "      name, \n",
        "      lat, \n",
        "      lng, \n",
        "      v['venue']['name'], \n",
        "      v['venue']['location']['lat'], \n",
        "      v['venue']['location']['lng'],  \n",
        "      v['venue']['categories'][0]['name']) for v in results])\n",
        "\n",
        "  nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
        "  nearby_venues.columns = ['Neighborhood', \n",
        "              'Neighborhood Latitude', \n",
        "              'Neighborhood Longitude', \n",
        "              'Venue', \n",
        "              'Venue Latitude', \n",
        "              'Venue Longitude', \n",
        "              'Venue Category']\n",
        "  \n",
        "  return(nearby_venues)\n",
        "toronto_venues = getNearbyVenues(names=toronto_data['Neighborhood'], latitudes=toronto_data['Latitude'], longitudes=toronto_data['Longitude'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8aJcPxI9HXsf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Analysis of each neighbourhood**"
      ]
    },
    {
      "metadata": {
        "id": "Ku9dXB38536P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "toronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
        "\n",
        "# add neighborhood column back to dataframe\n",
        "toronto_onehot['Neighborhood'] = toronto_venues['Neighborhood'] \n",
        "\n",
        "# move neighborhood column to the first column\n",
        "fixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\n",
        "toronto_onehot = toronto_onehot[fixed_columns]\n",
        "\n",
        "toronto_onehot.head()\n",
        "\n",
        "toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\n",
        "num_top_venues = 5\n",
        "\n",
        "for hood in toronto_grouped['Neighborhood']:\n",
        "  print(\"----\"+hood+\"----\")\n",
        "  temp = toronto_grouped[toronto_grouped['Neighborhood'] == hood].T.reset_index()\n",
        "  temp.columns = ['venue','freq']\n",
        "  temp = temp.iloc[1:]\n",
        "  temp['freq'] = temp['freq'].astype(float)\n",
        "  temp = temp.round({'freq': 2})\n",
        "  print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
        "  print('\\n')\n",
        "\n",
        "def return_most_common_venues(row, num_top_venues):\n",
        "    row_categories = row.iloc[1:]\n",
        "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
        "    \n",
        "    return row_categories_sorted.index.values[0:num_top_venues]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGF2NZUJHmGm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Displaying the top 10 venues for each neighborhood**"
      ]
    },
    {
      "metadata": {
        "id": "vORTI8ik6SgR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_top_venues = 10\n",
        "\n",
        "indicators = ['st', 'nd', 'rd']\n",
        "\n",
        "# create columns according to number of top venues\n",
        "columns = ['Neighborhood']\n",
        "for ind in np.arange(num_top_venues):\n",
        "    try:\n",
        "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
        "    except:\n",
        "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
        "\n",
        "# create a new dataframe\n",
        "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
        "neighborhoods_venues_sorted['Neighborhood'] = toronto_grouped['Neighborhood']\n",
        "\n",
        "for ind in np.arange(toronto_grouped.shape[0]):\n",
        "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n",
        "\n",
        "neighborhoods_venues_sorted\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YZw0P3jHuVv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Clustering Neighbourhood**"
      ]
    },
    {
      "metadata": {
        "id": "aLWFyKI4H2KW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set number of clusters\n",
        "kclusters = 5\n",
        "\n",
        "toronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n",
        "\n",
        "# run k-means clustering\n",
        "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n",
        "\n",
        "# check cluster labels generated for each row in the dataframe\n",
        "kmeans.labels_[0:10]\n",
        "\n",
        "toronto_merged = toronto_data\n",
        "\n",
        "# add clustering labels\n",
        "toronto_merged['Cluster Labels'] = kmeans.labels_\n",
        "\n",
        "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\n",
        "toronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
        "\n",
        "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
        "\n",
        "# set color scheme for the clusters\n",
        "x = np.arange(kclusters)\n",
        "ys = [i+x+(i*x)**2 for i in range(kclusters)]\n",
        "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
        "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
        "\n",
        "# add markers to the map\n",
        "markers_colors = []\n",
        "for lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighborhood'], toronto_merged['Cluster Labels']):\n",
        "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
        "    folium.CircleMarker(\n",
        "        [lat, lon],\n",
        "        radius=5,\n",
        "        popup=label,\n",
        "        color=rainbow[cluster-1],\n",
        "        fill=True,\n",
        "        fill_color=rainbow[cluster-1],\n",
        "        fill_opacity=0.7).add_to(map_clusters)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}